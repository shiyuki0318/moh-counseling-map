name: Scheduled Data Update

on:
  # 設定排程：每天格林威治時間 00:00 執行 (台灣時間早上 8 點)
  schedule:
    - cron: '0 0 * * *'
  # 也可以手動運行
  workflow_dispatch:

jobs:
  run_scraper_and_update_data:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository code
        uses: actions/checkout@v4

      # 步驟 A: 安裝 Chrome/Chromedriver
      - name: Install necessary tools (Chromium)
        run: |
          sudo apt-get update
          # 安裝無頭 Chrome 瀏覽器
          sudo apt-get install chromium-browser -y
          # 安裝 ChromeDriver
          sudo apt-get install chromium-chromedriver -y
          
      - name: Set up Python environment
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'

      # *** 關鍵修正：確保安裝 pandas 和所有 data science 套件 ***
      - name: Install dependencies (Scraper, Pandas, Geopy)
        run: |
          # 1. 安裝 requirements.txt 中的 web 套件 (streamlit, selenium, etc.)
          pip install -r requirements.txt
          # 2. 修正錯誤：明確安裝 pandas、geopy 和 BeautifulSoup
          pip install pandas geopy beautifulsoup4

      # 步驟 B: 執行爬蟲和地理編碼 (確保 Python 執行檔能夠找到)
      - name: Run Scraper and Geocoding
        run: |
          echo "--- Starting Scraper ---"
          # 執行爬蟲：現在 pandas 已經安裝了
          python auto_scraper.py 
          
          echo "--- Starting Geocoding ---"
          # 執行地理編碼
          python geocode.py

      # 步驟 C: 提交更新的資料
      - name: Commit and Push new data to GitHub
        run: |
          git config user.name 'GitHub Actions'
          git config user.email 'actions@github.com'
          # 檢查是否有任何變動 (避免錯誤)
          git add MOHW_counseling_data_FINAL.csv
          git commit -m "SCHEDULER: Auto update counseling data with latest availability." || echo "No changes to commit"
          git push
