import streamlit as st
import pandas as pd
import folium
import geopy.distance 
from streamlit_folium import st_folium 
from geopy.geocoders import ArcGIS 
from folium.plugins import LocateControl, MarkerCluster
import sys 
import os 
import time
import math 
import urllib3
from bs4 import BeautifulSoup 

# --- å°å…¥ Selenium å’Œ Webdriver Manager ---
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import Select
from selenium.common.exceptions import NoSuchElementException, TimeoutException
from selenium.webdriver.support.ui import WebDriverWait 
from selenium.webdriver.support import expected_conditions as EC 
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager 

# --- 0. å®šç¾©æª”æ¡ˆåç¨± ---
RAW_DATA_CSV = "MOHW_counseling_data_NEW.csv" # çˆ¬èŸ²åŸå§‹æª”
FINAL_DATA_CSV = "MOHW_counseling_data_FINAL.csv" # åŒ…å«ç¶“ç·¯åº¦çš„æœ€çµ‚æª”

# ==============================================================================
# 
# å€å¡Š Aï¼šçˆ¬èŸ² (Auto-Scraper)
# (é€™å°±æ˜¯æ‚¨æˆåŠŸçš„ Plan M ç¨‹å¼ç¢¼ï¼Œè¢«åŒ…æˆäº†ä¸€å€‹å‡½æ•¸)
#
# ==============================================================================
def run_scraper(status_placeholder):
    """
    åŸ·è¡Œã€Œéš±å½¢ã€çš„ Selenium çˆ¬èŸ² (Plan M)ï¼ŒæŠ“å–æœ€æ–°è³‡æ–™ã€‚
    """
    status_placeholder.warning("STEP 1/3: æ­£åœ¨å•Ÿå‹• Selenium çˆ¬èŸ² (åœ¨èƒŒæ™¯åŸ·è¡Œï¼Œè«‹ç¨å€™ 1-2 åˆ†é˜)...")
    
    main_page_url = "https://sps.mohw.gov.tw/mhs"
    inst_api_url = "https://sps.mohw.gov.tw/mhs/Home/QueryServiceOrgJsonList" 
    all_institutions_data = [] 
    county_map = {} 
    token = ""
    driver = None 

    try:
        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
        
        service = Service(ChromeDriverManager().install())
        options = webdriver.ChromeOptions()
        options.add_argument('--headless') # (é‡è¦) å•Ÿç”¨ headless æ¨¡å¼ï¼Œåœ¨èƒŒæ™¯åŸ·è¡Œ
        options.add_argument('--log-level=3') 
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        driver = webdriver.Chrome(service=service, options=options)
        
        wait = WebDriverWait(driver, 10) 
        driver.get(main_page_url)
        
        # 2.3 è™•ç† Cookie
        try:
            cookie_accept_button = wait.until(EC.element_to_be_clickable((By.XPATH, "//*[contains(text(), 'åŒæ„') or contains(text(), 'æ¥å—')]")))
            cookie_accept_button.click()
            time.sleep(1) 
        except Exception:
            pass # æ‰¾ä¸åˆ° Cookie è¦–çª—ä¹Ÿæ²’é—œä¿‚

        # 2.4 é»æ“Šã€ŒæŸ¥è©¢ã€æŒ‰éˆ•
        query_button_xpath = "//a[@class='queryServiceOrg']"
        query_button = wait.until(EC.element_to_be_clickable((By.XPATH, query_button_xpath)))
        query_button.click()
        time.sleep(1) 

        # 2.5 å°‹æ‰¾ Token
        token_element = wait.until(EC.presence_of_element_located((By.NAME, "__RequestVerificationToken")))
        token = token_element.get_attribute('value')

        # 2.6 å°‹æ‰¾ç¸£å¸‚
        county_select_element = wait.until(EC.visibility_of_element_located((By.ID, "county")))
        county_select = Select(county_select_element)
        for option in county_select.options:
            value = option.get_attribute('value')
            name = option.text
            if value: county_map[value] = name
        
        status_placeholder.warning("STEP 1/3: çˆ¬èŸ²å·²å•Ÿå‹•ï¼Œæ­£åœ¨é€é æŠ“å–è³‡æ–™...")

        # 3. (Plan M) åŸ·è¡Œ JS + è™•ç†ã€ŒçœŸå¯¦åˆ†é ã€
        js_fetch_script = """
        var api_url = arguments[0], token = arguments[1], county_code = arguments[2];
        var page_size = arguments[3], now_page = arguments[4];
        var callback = arguments[5];
        var params = new URLSearchParams();
        params.append('__RequestVerificationToken', token);
        params.append('county', county_code);
        params.append('orgName', '');
        params.append('NowPage', now_page);
        params.append('PageSize', page_size);
        params.append('FirstSearch', 'true');
        params.append('sortCol', '');
        params.append('sortMode', '');
        fetch(api_url, {
            method: 'POST',
            headers: {'X-Requested-With': 'XMLHttpRequest', 'Origin': window.location.origin, 'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8'},
            body: params.toString()
        }).then(response => response.json()).then(data => callback(data)).catch(error => callback({ 'error': error.toString() }));
        """
        driver.set_script_timeout(30) 
        PAGE_SIZE = 10 
        
        for county_code, county_name in county_map.items():
            status_placeholder.warning(f"STEP 1/3: æ­£åœ¨çˆ¬å– {county_name}...")
            # ç¬¬ä¸€æ¬¡è«‹æ±‚ (åµæŸ¥)
            api_response = driver.execute_async_script(js_fetch_script, inst_api_url, token, county_code, PAGE_SIZE, 1)
            total_records = api_response.get('total', 0)
            institutions_in_page = api_response.get('rows', [])
            if total_records == 0 or not institutions_in_page: continue
            
            for inst in institutions_in_page: inst['scraped_county_name'] = county_name
            all_institutions_data.extend(institutions_in_page)
            
            total_pages = math.ceil(total_records / PAGE_SIZE)
            
            # å­è¿´åœˆï¼šçˆ¬å– Page 2 åˆ°æœ€å¾Œä¸€é 
            if total_pages > 1:
                for page_num in range(2, total_pages + 1):
                    api_response_page = driver.execute_async_script(js_fetch_script, inst_api_url, token, county_code, PAGE_SIZE, page_num)
                    if 'error' in api_response_page: continue 
                    institutions_in_page = api_response_page.get('rows', [])
                    for inst in institutions_in_page: inst['scraped_county_name'] = county_name
                    all_institutions_data.extend(institutions_in_page)
                    time.sleep(0.3) # ç¦®è²Œæ€§æš«åœ
        
        status_placeholder.success("STEP 1/3: çˆ¬èŸ²åŸ·è¡Œå®Œç•¢ï¼")

    except Exception as e:
        status_placeholder.error(f"çˆ¬èŸ²åŸ·è¡Œå¤±æ•—: {e}")
        return False
    finally:
        if driver:
            driver.quit()

    # 5. å„²å­˜åŸå§‹è³‡æ–™
    if not all_institutions_data:
        status_placeholder.error("çˆ¬èŸ²æœªæŠ“åˆ°ä»»ä½•è³‡æ–™ã€‚")
        return False
        
    df = pd.DataFrame(all_institutions_data)
    df.to_csv(RAW_DATA_CSV, index=False, encoding='utf-8-sig')
    status_placeholder.success(f"STEP 1/3: åŸå§‹è³‡æ–™å·²å„²å­˜è‡³ {RAW_DATA_CSV}")
    return True

# ==============================================================================
# 
# å€å¡Š Bï¼šåœ°ç†ç·¨ç¢¼ (Geocoding)
# (é€™å°±æ˜¯æ‚¨æˆåŠŸçš„ ArcGIS v2 ç¨‹å¼ç¢¼ï¼Œè¢«åŒ…æˆäº†ä¸€å€‹å‡½æ•¸)
#
# ==============================================================================
def run_geocoding(status_placeholder):
    """
    è®€å– RAW_DATA_CSVï¼Œå°‡åœ°å€è½‰ç‚ºç¶“ç·¯åº¦ï¼Œå„²å­˜ç‚º FINAL_DATA_CSV
    """
    status_placeholder.warning(f"STEP 2/3: æ­£åœ¨åŸ·è¡Œã€Œåœ°ç†ç·¨ç¢¼ã€(å°‡åœ°å€è½‰ç‚ºç¶“ç·¯åº¦)...")
    status_placeholder.info("é€™ä¸€æ­¥æœƒèŠ± 5-10 åˆ†é˜ï¼Œå› ç‚ºå…è²»æœå‹™æœ‰é™é€Ÿï¼Œè«‹è€å¿ƒç­‰å¾…ã€‚")
    
    try:
        df = pd.read_csv(RAW_DATA_CSV)
    except FileNotFoundError:
        status_placeholder.error(f"æ‰¾ä¸åˆ°çˆ¬èŸ²çš„åŸå§‹æª” {RAW_DATA_CSV}ï¼")
        return False

    geolocator = ArcGIS(timeout=10)
    geocode = RateLimiter(geolocator.geocode, min_delay_seconds=0.5, error_wait_seconds=5.0)
    
    latitudes = []
    longitudes = []
    count = 0
    total = len(df)

    for address in df['address']:
        count += 1
        if pd.isna(address) or address.strip() == "":
            latitudes.append(None)
            longitudes.append(None)
            continue

        # (æ–°) å³æ™‚æ›´æ–°ç‹€æ…‹
        status_placeholder.info(f"STEP 2/3: æ­£åœ¨æŸ¥è©¢ç¶“ç·¯åº¦ ({count}/{total}): {address} ...")
        
        try:
            location = geocode(address)
            if location:
                latitudes.append(location.latitude)
                longitudes.append(location.longitude)
            else:
                latitudes.append(None)
                longitudes.append(None)
        except Exception:
            latitudes.append(None)
            longitudes.append(None)
    
    df['lat'] = latitudes
    df['lng'] = longitudes
    
    # (æ–°) æ¸…æ´— HTML æ¨™ç±¤
    def clean_html(raw_html):
        if pd.isna(raw_html): return ""
        return BeautifulSoup(str(raw_html), 'html.parser').get_text()

    if 'orgName' in df.columns: df['orgName'] = df['orgName'].apply(clean_html)
    if 'address' in df.columns: df['address'] = df['address'].apply(clean_html)

    # å„²å­˜æœ€çµ‚æª”æ¡ˆ
    df.to_csv(FINAL_DATA_CSV, index=False, encoding='utf-8-sig')
    status_placeholder.success(f"STEP 2/3: ç¶“ç·¯åº¦è½‰æ›å®Œç•¢ï¼Œå·²å„²å­˜è‡³ {FINAL_DATA_CSV}")
    return True

# ==============================================================================
# 
# å€å¡Š Cï¼šStreamlit APP ä¸»é«” (v4 - é›™æ¨¡å¼)
#
# ==============================================================================

# --- 1. è¼‰å…¥è³‡æ–™ (å¿«å–) ---
@st.cache_data 
def load_data(csv_file):
    try:
        df = pd.read_csv(csv_file)
        df = df.dropna(subset=['lat', 'lng'])
        # é å…ˆè™•ç†åé¡ï¼Œå°‡ None è½‰ç‚º 0
        df['thisWeekCount'] = pd.to_numeric(df['thisWeekCount'], errors='coerce').fillna(0).astype(int)
        # (å…¶ä»–åé¡æ¬„ä½ä¹Ÿä¸€ä½µè™•ç†)
        return df
    except FileNotFoundError:
        return None # (æ–°) æ‰¾ä¸åˆ°æª”æ¡ˆæ™‚å›å‚³ None
    except Exception as e:
        st.error(f"è®€å–è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

# --- 2. å®šä½ä½¿ç”¨è€…åœ°å€ (å¿«å–) ---
@st.cache_data 
def get_user_location(address):
    if not address: return None
    try:
        geolocator = ArcGIS(timeout=5)
        location = geolocator.geocode(address)
        if location: return (location.latitude, location.longitude)
        else: return None
    except Exception: return None

# --- 3. APP ä¸»ç¨‹å¼ ---
st.set_page_config(page_title="å…¬è²»å¿ƒç†è«®å•†åœ°åœ–", layout="wide")
st.title("ğŸ¥ å…¬è²»å¿ƒç†è«®å•† - å³æ™‚åœ°åœ–æœå°‹ç³»çµ± (çµ‚æ¥µç‰ˆ)")
st.write("æ‚¨å¯ä»¥é¸æ“‡ã€Œé›¢æˆ‘æœ€è¿‘ã€ä¾†æœå°‹ï¼Œæˆ–ã€Œç€è¦½å…¨å°ã€ä¾†æŸ¥çœ‹ç‰¹å®šç¸£å¸‚çš„è³‡æºã€‚")

# (æ–°) å»ºç«‹ä¸€å€‹ã€Œç‹€æ…‹é¡¯ç¤ºå€ã€ï¼Œç”¨æ–¼é¡¯ç¤ºæ›´æ–°é€²åº¦
status_placeholder = st.empty()

# --- æª¢æŸ¥è³‡æ–™åº«æ˜¯å¦å­˜åœ¨ ---
df_all = load_data(FINAL_DATA_CSV)

if df_all is None:
    # --- æƒ…æ³ Aï¼šç¬¬ä¸€æ¬¡åŸ·è¡Œï¼Œè³‡æ–™åº«ä¸å­˜åœ¨ ---
    st.error(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æœ€çµ‚è³‡æ–™æª” '{FINAL_DATA_CSV}'ï¼")
    st.warning("é€™å¯èƒ½æ˜¯æ‚¨ç¬¬ä¸€æ¬¡åŸ·è¡Œæœ¬ç¨‹å¼ã€‚")
    if st.button("é»æ­¤é–‹å§‹ã€Œåˆå§‹åŒ–è³‡æ–™åº«ã€(å°‡åŸ·è¡Œçˆ¬èŸ²èˆ‡åœ°ç†ç·¨ç¢¼ï¼Œç´„éœ€ 10-15 åˆ†é˜)"):
        
        # åŸ·è¡Œçˆ¬èŸ²
        scraper_success = run_scraper(status_placeholder)
        
        # å¦‚æœçˆ¬èŸ²æˆåŠŸï¼Œæ‰åŸ·è¡Œåœ°ç†ç·¨ç¢¼
        if scraper_success:
            geocoding_success = run_geocoding(status_placeholder)
            
            if geocoding_success:
                status_placeholder.success("âœ… è³‡æ–™åº«åˆå§‹åŒ–å®Œæˆï¼æ­£åœ¨é‡æ–°è¼‰å…¥ APP...")
                time.sleep(2)
                st.rerun() # é‡æ–°æ•´ç†é é¢
            else:
                status_placeholder.error("âŒ åœ°ç†ç·¨ç¢¼å¤±æ•—ï¼Œè«‹æª¢æŸ¥éŒ¯èª¤è¨Šæ¯ã€‚")
        else:
            status_placeholder.error("âŒ çˆ¬èŸ²å¤±æ•—ï¼Œè«‹æª¢æŸ¥éŒ¯èª¤è¨Šæ¯ã€‚")
else:
    # --- æƒ…æ³ Bï¼šè³‡æ–™åº«å·²å­˜åœ¨ï¼Œæ­£å¸¸åŸ·è¡Œ APP ---
    
    # 3. å»ºç«‹å´é‚Šæ¬„ (Sidebar) ç¯©é¸å™¨ ---
    st.sidebar.header("Step 1: é¸æ“‡æœå°‹æ¨¡å¼")
    search_mode = st.sidebar.radio("æ‚¨æƒ³å¦‚ä½•æœå°‹ï¼Ÿ", ('é›¢æˆ‘æœ€è¿‘', 'ç€è¦½å…¨å°'))
    st.sidebar.header("Step 2: è¨­å®šç¯©é¸æ¢ä»¶")

    df_filtered = df_all.copy() 
    user_loc = None
    map_center = [23.9738, 120.982] # é è¨­åœ°åœ–ä¸­å¿ƒ (å°ç£)
    map_zoom = 8 # é è¨­ç¸®æ”¾ (å…¨å°ç£)

    if search_mode == 'é›¢æˆ‘æœ€è¿‘':
        st.sidebar.subheader("ğŸ“ æ‚¨çš„ä½ç½®")
        user_address = st.sidebar.text_input("è¼¸å…¥æ‚¨çš„åœ°å€", "è‡ºåŒ—å¸‚ä¸­æ­£å€é‡æ…¶å—è·¯ä¸€æ®µ122è™Ÿ")
        distance_km = st.sidebar.slider("æœå°‹ç¯„åœ (å…¬é‡Œ)", 1.0, 10.0, 3.0, 0.5)
        user_loc = get_user_location(user_address)
        
        if user_loc:
            st.sidebar.success(f"å®šä½æˆåŠŸ: {user_address}")
            map_center = [user_loc[0], user_loc[1]] 
            map_zoom = 13 
            df_filtered['distance'] = df_filtered.apply(
                lambda row: geopy.distance.great_circle(user_loc, (row['lat'], row['lng'])).km,
                axis=1
            )
            df_filtered = df_filtered[df_filtered['distance'] <= distance_km]
        else:
            st.warning("è«‹åœ¨å·¦å´è¼¸å…¥æœ‰æ•ˆçš„åœ°å€ä»¥å•Ÿç”¨ã€Œé›¢æˆ‘æœ€è¿‘ã€æœå°‹ã€‚")

    else: # æ¨¡å¼ B: ç€è¦½å…¨å°
        st.sidebar.subheader("ğŸŒ ç€è¦½å…¨å°")
        counties = ['[ å…¨é¸ ]'] + sorted(df_all['scraped_county_name'].unique())
        selected_counties = st.sidebar.multiselect("ç¯©é¸ç¸£å¸‚", counties, default=['[ å…¨é¸ ]'])
        
        if '[ å…¨é¸ ]' not in selected_counties:
            df_filtered = df_filtered[df_filtered['scraped_county_name'].isin(selected_counties)]

    # é€šç”¨ç¯©é¸å™¨ï¼šå‰©é¤˜åé¡ (å…©å€‹æ¨¡å¼å…±ç”¨)
    min_slots = st.sidebar.slider("æœ¬é€±è‡³å°‘å‰©é¤˜åé¡", 0, 20, 1, 1)
    df_filtered = df_filtered[df_filtered['thisWeekCount'] >= min_slots]
        
    # 4. è³‡æ–™æ›´æ–°åŠŸèƒ½
    st.sidebar.header("è³‡æ–™æ›´æ–° (æ‰‹å‹•)")
    last_mod_time = os.path.getmtime(FINAL_DATA_CSV)
    st.sidebar.caption(f"è³‡æ–™æœ€å¾Œæ›´æ–°: {time.ctime(last_mod_time)}")
    
    if st.sidebar.button("åŸ·è¡Œçˆ¬èŸ²ï¼Œæ›´æ–°æœ€æ–°åé¡"):
        scraper_success = run_scraper(status_placeholder)
        if scraper_success:
            geocoding_success = run_geocoding(status_placeholder)
            if geocoding_success:
                status_placeholder.success("âœ… è³‡æ–™åº«æ›´æ–°å®Œæˆï¼æ­£åœ¨é‡æ–°è¼‰F APP...")
                st.cache_data.clear() # (é‡è¦) æ¸…é™¤èˆŠçš„å¿«å–
                time.sleep(2)
                st.rerun() # é‡æ–°æ•´ç†é é¢
            else:
                status_placeholder.error("âŒ åœ°ç†ç·¨ç¢¼å¤±æ•—ï¼Œè«‹æª¢æŸ¥éŒ¯èª¤è¨Šæ¯ã€‚")
        else:
            status_placeholder.error("âŒ çˆ¬èŸ²å¤±æ•—ï¼Œè«‹æª¢æŸ¥éŒ¯èª¤è¨Šæ¯ã€‚")

    # 5. è¦–è¦ºåŒ–ï¼šåœ¨åœ°åœ–ä¸Šé¡¯ç¤ºçµæœ
    m = folium.Map(location=map_center, zoom_start=map_zoom) 
    LocateControl(auto_start=False, strings={"title": "é¡¯ç¤ºæˆ‘ç¾åœ¨çš„ä½ç½®", "popup": "æ‚¨åœ¨é€™è£¡"}).add_to(m)
    marker_cluster = MarkerCluster().add_to(m)

    if search_mode == 'é›¢æˆ‘æœ€è¿‘' and user_loc:
        folium.Marker(location=user_loc, popup=f"<b>æ‚¨çš„ä½ç½®</b>", icon=folium.Icon(color="red", icon="user")).add_to(m)

    if df_filtered.empty:
        st.warning("åœ¨åœ°åœ–ç¯„åœå…§æ‰¾ä¸åˆ°ç¬¦åˆæ¢ä»¶çš„è¨ºæ‰€ã€‚è«‹èª¿æ•´ç¯©é¸å™¨ã€‚")
    else:
        st.success(f"åœ¨åœ°åœ–ç¯„åœå…§æ‰¾åˆ° {len(df_filtered)} é–“ç¬¦åˆæ¢ä»¶çš„è¨ºæ‰€ï¼š")
        
        for idx, row in df_filtered.iterrows():
            if row['thisWeekCount'] > 0: marker_color = 'green'; icon_name = 'check' 
            else: marker_color = 'blue'; icon_name = 'medkit' 
            
            popup_html = f"<b>{row['orgName']}</b><hr style='margin: 3px;'>"
            if 'distance' in df_filtered.columns:
                 popup_html += f"<b>è·é›¢:</b> {row['distance']:.2f} å…¬é‡Œ<br>"
            popup_html += f"<b>æœ¬é€±åé¡:</b> <b>{int(row['thisWeekCount'])}</b><br><b>åœ°å€:</b> {row['address']}<br><b>é›»è©±:</b> {row['phone']}"
            
            folium.Marker(
                location=[row['lat'], row['lng']],
                popup=folium.Popup(popup_html, max_width=300),
                icon=folium.Icon(color=marker_color, icon=icon_name, prefix='fa')
            ).add_to(marker_cluster) 
            
        st_folium(m, width="100%", height=500, returned_objects=[])
        
        # 6. é¡¯ç¤ºè¡¨æ ¼
        st.subheader("è©³ç´°è³‡æ–™åˆ—è¡¨")
        display_columns = ['orgName', 'thisWeekCount', 'scraped_county_name', 'address', 'phone', 'payDetail']
        if 'distance' in df_filtered.columns:
            display_columns.insert(1, 'distance') 
            st.dataframe(df_filtered.sort_values(by='distance')[display_columns].style.format({'distance': '{:.2f} km'}))
        else:
            st.dataframe(df_filtered[display_columns])